{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'Pris is awesome.'\n",
      "Subject: 'Pris' → Entity: ORG\n",
      "Sentence: 'My friend is there.'\n",
      "Subject: 'friend' → Entity: UNKNOWN\n",
      "Sentence: 'Peter is the worst'\n",
      "Subject: 'Peter' → Entity: PERSON\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "\n",
    "# # Clean install of working NER pipeline (no curated_transformer)\n",
    "# !{sys.executable} -m pip uninstall -y spacy spacy-transformers spacy-curated-transformers\n",
    "# !{sys.executable} -m pip install spacy==3.7.2\n",
    "# !{sys.executable} -m spacy download en_core_web_lg\n",
    "\n",
    "# Load large English model\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Test\n",
    "text = \"Pris is awesome. Its the best city. My friend is there. Peter is the worst\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract subject + entity label\n",
    "for sent in doc.sents:\n",
    "    subject = None\n",
    "    for token in sent:\n",
    "        if token.dep_ in ('nsubj', 'nsubjpass'):\n",
    "            subject = token\n",
    "            break\n",
    "    if subject:\n",
    "        ent_label = subject.ent_type_ if subject.ent_type_ else \"UNKNOWN\"\n",
    "        print(f\"Sentence: '{sent.text.strip()}'\")\n",
    "        print(f\"Subject: '{subject}' → Entity: {ent_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stygianphantom/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 59924/59924 [00:00<00:00, 1085952.98 examples/s]\n",
      "Generating validation split: 100%|██████████| 8528/8528 [00:00<00:00, 1803328.69 examples/s]\n",
      "Generating test split: 100%|██████████| 8262/8262 [00:00<00:00, 1659642.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"tner/ontonotes5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['tokens', 'tags'], 'validation': ['tokens', 'tags'], 'test': ['tokens', 'tags']}\n"
     ]
    }
   ],
   "source": [
    "print(ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping util as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping spacy as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping spacy-transformers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (25.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting spacy[transformers]\n",
      "  Using cached spacy-3.8.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from spacy[transformers]) (58.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy[transformers]) (3.5.0)\n",
      "Collecting spacy_transformers<1.4.0,>=1.1.2 (from spacy[transformers])\n",
      "  Downloading spacy_transformers-1.3.8-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from langcodes<4.0.0,>=3.2.0->spacy[transformers]) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[transformers]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[transformers]) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[transformers]) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2024.8.30)\n",
      "Requirement already satisfied: transformers<4.50.0,>=3.4.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (4.49.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (2.6.0)\n",
      "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy_transformers<1.4.0,>=1.1.2->spacy[transformers])\n",
      "  Downloading spacy_alignments-0.9.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from thinc<8.4.0,>=8.3.0->spacy[transformers]) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from thinc<8.4.0,>=8.3.0->spacy[transformers]) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy[transformers]) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy[transformers]) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy[transformers]) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from weasel<0.5.0,>=0.1.0->spacy[transformers]) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from weasel<0.5.0,>=0.1.0->spacy[transformers]) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from jinja2->spacy[transformers]) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy[transformers]) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[transformers]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[transformers]) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy[transformers]) (1.16.0)\n",
      "Requirement already satisfied: filelock in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from torch>=1.8.0->spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (3.18.0)\n",
      "Requirement already satisfied: networkx in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from torch>=1.8.0->spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from torch>=1.8.0->spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from torch>=1.8.0->spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch>=1.8.0->spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from transformers<4.50.0,>=3.4.0->spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (0.29.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from transformers<4.50.0,>=3.4.0->spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from transformers<4.50.0,>=3.4.0->spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from transformers<4.50.0,>=3.4.0->spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from transformers<4.50.0,>=3.4.0->spacy_transformers<1.4.0,>=1.1.2->spacy[transformers]) (0.5.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[transformers]) (0.1.2)\n",
      "Downloading spacy_transformers-1.3.8-cp39-cp39-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached spacy-3.8.3-cp39-cp39-macosx_11_0_arm64.whl (6.3 MB)\n",
      "Downloading spacy_alignments-0.9.1-cp39-cp39-macosx_11_0_arm64.whl (317 kB)\n",
      "Installing collected packages: spacy-alignments, spacy, spacy_transformers\n",
      "Successfully installed spacy-3.8.3 spacy-alignments-0.9.1 spacy_transformers-1.3.8\n",
      "/Users/stygianphantom/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-trf==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting spacy-curated-transformers<1.0.0,>=0.2.2 (from en-core-web-trf==3.8.0)\n",
      "  Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
      "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
      "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
      "  Downloading curated_tokenizers-0.0.9-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: torch>=1.12.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.6.0)\n",
      "Requirement already satisfied: regex>=2022 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.11.6)\n",
      "Requirement already satisfied: filelock in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/stygianphantom/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.2)\n",
      "Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl (236 kB)\n",
      "Downloading curated_tokenizers-0.0.9-cp39-cp39-macosx_11_0_arm64.whl (704 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.8/704.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: curated-tokenizers, curated-transformers, spacy-curated-transformers, en-core-web-trf\n",
      "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 en-core-web-trf-3.8.0 spacy-curated-transformers-0.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_trf')\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "\n",
    "# # Step 1: Fix pip installation into current Python kernel environment\n",
    "# !{sys.executable} -m pip uninstall -y util\n",
    "# !{sys.executable} -m pip uninstall -y spacy spacy-transformers\n",
    "# !{sys.executable} -m pip install -U pip\n",
    "# !{sys.executable} -m pip install \"spacy[transformers]\"\n",
    "# !{sys.executable} -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluated examples: 49595\n",
      "True Positive: 4109\n",
      "False Positive: 641\n",
      "False Negative: 329\n",
      "Precision: 0.865, Recall: 0.926, F1 Score: 0.894\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import spacy\n",
    "\n",
    "# Use a small subset for testing (first 100 examples)\n",
    "ds = load_dataset(\"tner/ontonotes5\", split=\"train\")\n",
    "\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "total_evaluated = 0\n",
    "\n",
    "# For each example in the dataset\n",
    "for example in ds:\n",
    "    tokens = example[\"tokens\"]       # e.g. [\"People\", \"start\", \"their\", ...]\n",
    "    tags = example[\"tags\"]           # e.g. [0, 0, 0, ...] where 4 means PERSON\n",
    "    \n",
    "    # Reconstruct sentence (simple join; note: tokenization differences may occur)\n",
    "    sentence = \" \".join(tokens)\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    subject_token = None\n",
    "    # Loop over sentences in the spaCy doc (usually one sentence per example)\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if token.dep_ in ('nsubj', 'nsubjpass'):\n",
    "                subject_token = token\n",
    "                break\n",
    "        if subject_token:\n",
    "            break\n",
    "    # If no subject was found, skip this example\n",
    "    if subject_token is None:\n",
    "        continue\n",
    "\n",
    "    # Try to align the subject token with the original tokens (using a case-insensitive match)\n",
    "    try:\n",
    "        token_index = next(i for i, t in enumerate(tokens) if t.lower() == subject_token.text.lower())\n",
    "    except StopIteration:\n",
    "        continue  # if not found, skip this example\n",
    "\n",
    "    # Ground truth: label 4 means PERSON\n",
    "    ground_truth_person = tags[token_index] == 4 or (\n",
    "        token_index > 0 and tags[token_index - 1] == 4\n",
    "    ) or (\n",
    "        token_index < len(tags) - 1 and tags[token_index + 1] == 4\n",
    "    )\n",
    "    # Prediction: our model's subject gets \"PERSON\" if spaCy marks it as such; otherwise, we treat it as not PERSON.\n",
    "    predicted_person = any(\n",
    "        ent.label_ == \"PERSON\" and subject_token.idx >= ent.start_char and subject_token.idx < ent.end_char\n",
    "        for ent in doc.ents\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Count outcomes\n",
    "    if predicted_person and ground_truth_person:\n",
    "        true_positive += 1\n",
    "    elif predicted_person and not ground_truth_person:\n",
    "        false_positive += 1\n",
    "    elif not predicted_person and ground_truth_person:\n",
    "        false_negative += 1\n",
    "\n",
    "    total_evaluated += 1\n",
    "\n",
    "# Calculate metrics\n",
    "precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"Total evaluated examples:\", total_evaluated)\n",
    "print(\"True Positive:\", true_positive)\n",
    "print(\"False Positive:\", false_positive)\n",
    "print(\"False Negative:\", false_negative)\n",
    "print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives (Model predicted PERSON but GT is NOT_PERSON):\n",
      "\n",
      "Example 1:\n",
      "Sentence       : John B. Curcio , 55 years old , resigned as chairman of this diesel truck manufacturer , effective upon appointment of a successor .\n",
      "Tokens         : ['John', 'B.', 'Curcio', ',', '55', 'years', 'old', ',', 'resigned', 'as', 'chairman', 'of', 'this', 'diesel', 'truck', 'manufacturer', ',', 'effective', 'upon', 'appointment', 'of', 'a', 'successor', '.']\n",
      "Subject token  : Curcio\n",
      "Token index    : 2\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 2:\n",
      "Sentence       : Richard W. Lock , retired vice president and treasurer of Owens - Illinois Inc. , was named a director of this transportation industry supplier , increasing its board to six members .\n",
      "Tokens         : ['Richard', 'W.', 'Lock', ',', 'retired', 'vice', 'president', 'and', 'treasurer', 'of', 'Owens', '-', 'Illinois', 'Inc.', ',', 'was', 'named', 'a', 'director', 'of', 'this', 'transportation', 'industry', 'supplier', ',', 'increasing', 'its', 'board', 'to', 'six', 'members', '.']\n",
      "Subject token  : Lock\n",
      "Token index    : 2\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 3:\n",
      "Sentence       : Retired Adm. William J. Crowe , former chairman of the Joint Chiefs of Staff , and Robert P. Luciano , chairman and chief executive officer of Schering - Plough Corp. , were elected directors of this securities firm .\n",
      "Tokens         : ['Retired', 'Adm.', 'William', 'J.', 'Crowe', ',', 'former', 'chairman', 'of', 'the', 'Joint', 'Chiefs', 'of', 'Staff', ',', 'and', 'Robert', 'P.', 'Luciano', ',', 'chairman', 'and', 'chief', 'executive', 'officer', 'of', 'Schering', '-', 'Plough', 'Corp.', ',', 'were', 'elected', 'directors', 'of', 'this', 'securities', 'firm', '.']\n",
      "Subject token  : Crowe\n",
      "Token index    : 4\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 4:\n",
      "Sentence       : Roy E. Parrott , the company 's president and chief operating officer since Sept. 1 , was named to its board .\n",
      "Tokens         : ['Roy', 'E.', 'Parrott', ',', 'the', 'company', \"'s\", 'president', 'and', 'chief', 'operating', 'officer', 'since', 'Sept.', '1', ',', 'was', 'named', 'to', 'its', 'board', '.']\n",
      "Subject token  : Parrott\n",
      "Token index    : 2\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 5:\n",
      "Sentence       : Malcolm S. Todt was named vice president and senior officer in charge of equipment leasing to municipalities , a new effort of this bond insurer .\n",
      "Tokens         : ['Malcolm', 'S.', 'Todt', 'was', 'named', 'vice', 'president', 'and', 'senior', 'officer', 'in', 'charge', 'of', 'equipment', 'leasing', 'to', 'municipalities', ',', 'a', 'new', 'effort', 'of', 'this', 'bond', 'insurer', '.']\n",
      "Subject token  : Todt\n",
      "Token index    : 2\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 6:\n",
      "Sentence       : Industry analyst John H. Qualls , a vice president with Hill & Knowlton in St. Louis , forecasts that domestic auto makers will have a 93 - day supply of cars at the end of the year , even if car sales improve to a 6.5 million vehicle rate for the quarter .\n",
      "Tokens         : ['Industry', 'analyst', 'John', 'H.', 'Qualls', ',', 'a', 'vice', 'president', 'with', 'Hill', '&', 'Knowlton', 'in', 'St.', 'Louis', ',', 'forecasts', 'that', 'domestic', 'auto', 'makers', 'will', 'have', 'a', '93', '-', 'day', 'supply', 'of', 'cars', 'at', 'the', 'end', 'of', 'the', 'year', ',', 'even', 'if', 'car', 'sales', 'improve', 'to', 'a', '6.5', 'million', 'vehicle', 'rate', 'for', 'the', 'quarter', '.']\n",
      "Subject token  : Qualls\n",
      "Token index    : 4\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 7:\n",
      "Sentence       : Creator Hugh Wilson , for example , included the lead character 's Greek family in the cast , `` but that is not the right focus anymore , '' said one CBS executive .\n",
      "Tokens         : ['Creator', 'Hugh', 'Wilson', ',', 'for', 'example', ',', 'included', 'the', 'lead', 'character', \"'s\", 'Greek', 'family', 'in', 'the', 'cast', ',', '``', 'but', 'that', 'is', 'not', 'the', 'right', 'focus', 'anymore', ',', \"''\", 'said', 'one', 'CBS', 'executive', '.']\n",
      "Subject token  : Wilson\n",
      "Token index    : 2\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 8:\n",
      "Sentence       : Judge Robert -LRB- `` Maximum Bob '' -RRB- Potter sentenced Jim Bakker to 45 years in the big house yesterday , while a Beverly Hills judge tucked away Zsa Zsa Gabor for three days , plus 120 hours of work with homeless women .\n",
      "Tokens         : ['Judge', 'Robert', '-LRB-', '``', 'Maximum', 'Bob', \"''\", '-RRB-', 'Potter', 'sentenced', 'Jim', 'Bakker', 'to', '45', 'years', 'in', 'the', 'big', 'house', 'yesterday', ',', 'while', 'a', 'Beverly', 'Hills', 'judge', 'tucked', 'away', 'Zsa', 'Zsa', 'Gabor', 'for', 'three', 'days', ',', 'plus', '120', 'hours', 'of', 'work', 'with', 'homeless', 'women', '.']\n",
      "Subject token  : Potter\n",
      "Token index    : 8\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 9:\n",
      "Sentence       : Now along comes Stephen Jay Gould to dash this flattering illusion .\n",
      "Tokens         : ['Now', 'along', 'comes', 'Stephen', 'Jay', 'Gould', 'to', 'dash', 'this', 'flattering', 'illusion', '.']\n",
      "Subject token  : Gould\n",
      "Token index    : 5\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 10:\n",
      "Sentence       : In a memorandum describing the guidelines , Assistant Attorney General Edward Dennis Jr. said that government efforts to freeze defendants ' assets pending racketeering prosecutions `` have been the subject of considerable criticism in the press . ''\n",
      "Tokens         : ['In', 'a', 'memorandum', 'describing', 'the', 'guidelines', ',', 'Assistant', 'Attorney', 'General', 'Edward', 'Dennis', 'Jr.', 'said', 'that', 'government', 'efforts', 'to', 'freeze', 'defendants', \"'\", 'assets', 'pending', 'racketeering', 'prosecutions', '``', 'have', 'been', 'the', 'subject', 'of', 'considerable', 'criticism', 'in', 'the', 'press', '.', \"''\"]\n",
      "Subject token  : Jr.\n",
      "Token index    : 12\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "\n",
      "False Negatives (Model predicted NOT_PERSON but GT is PERSON):\n",
      "\n",
      "Example 1:\n",
      "Sentence       : The Bush administration said it is submitting a `` comprehensive '' proposal for overhauling agricultural trade that could help break an impasse in the current round of multilateral trade negotiations .\n",
      "Tokens         : ['The', 'Bush', 'administration', 'said', 'it', 'is', 'submitting', 'a', '``', 'comprehensive', \"''\", 'proposal', 'for', 'overhauling', 'agricultural', 'trade', 'that', 'could', 'help', 'break', 'an', 'impasse', 'in', 'the', 'current', 'round', 'of', 'multilateral', 'trade', 'negotiations', '.']\n",
      "Subject token  : administration\n",
      "Token index    : 2\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 2:\n",
      "Sentence       : And Beauregard was mentioned twice -- although very briefly and in passing . ''\n",
      "Tokens         : ['And', 'Beauregard', 'was', 'mentioned', 'twice', '--', 'although', 'very', 'briefly', 'and', 'in', 'passing', '.', \"''\"]\n",
      "Subject token  : Beauregard\n",
      "Token index    : 1\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 3:\n",
      "Sentence       : `` Norm Berry was a creative inspiration at the company , and nobody has filled that void , '' said Ms. Hill .\n",
      "Tokens         : ['``', 'Norm', 'Berry', 'was', 'a', 'creative', 'inspiration', 'at', 'the', 'company', ',', 'and', 'nobody', 'has', 'filled', 'that', 'void', ',', \"''\", 'said', 'Ms.', 'Hill', '.']\n",
      "Subject token  : Berry\n",
      "Token index    : 2\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 4:\n",
      "Sentence       : `` Anne does n't believe in blandness , '' said Ms. Smith .\n",
      "Tokens         : ['``', 'Anne', 'does', \"n't\", 'believe', 'in', 'blandness', ',', \"''\", 'said', 'Ms.', 'Smith', '.']\n",
      "Subject token  : Anne\n",
      "Token index    : 1\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 5:\n",
      "Sentence       : The Ochoa trial in July , with its revelations of deeply rooted and widespread corruption , and the summary trial and execution , was extremely disturbing to everyone who has ever considered himself a friend of Cuba .\n",
      "Tokens         : ['The', 'Ochoa', 'trial', 'in', 'July', ',', 'with', 'its', 'revelations', 'of', 'deeply', 'rooted', 'and', 'widespread', 'corruption', ',', 'and', 'the', 'summary', 'trial', 'and', 'execution', ',', 'was', 'extremely', 'disturbing', 'to', 'everyone', 'who', 'has', 'ever', 'considered', 'himself', 'a', 'friend', 'of', 'Cuba', '.']\n",
      "Subject token  : trial\n",
      "Token index    : 2\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 6:\n",
      "Sentence       : The Bush administration ought to be setting aside some of its buckshot for the non-duck ducks .\n",
      "Tokens         : ['The', 'Bush', 'administration', 'ought', 'to', 'be', 'setting', 'aside', 'some', 'of', 'its', 'buckshot', 'for', 'the', 'non-duck', 'ducks', '.']\n",
      "Subject token  : administration\n",
      "Token index    : 2\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 7:\n",
      "Sentence       : Roe vs. Wade was the Supreme Court 's 1973 decision that recognized a woman 's right to abortion .\n",
      "Tokens         : ['Roe', 'vs.', 'Wade', 'was', 'the', 'Supreme', 'Court', \"'s\", '1973', 'decision', 'that', 'recognized', 'a', 'woman', \"'s\", 'right', 'to', 'abortion', '.']\n",
      "Subject token  : Roe\n",
      "Token index    : 0\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 8:\n",
      "Sentence       : The Barre dictatorship simply is limited in the amount of people it can torture and kill .\n",
      "Tokens         : ['The', 'Barre', 'dictatorship', 'simply', 'is', 'limited', 'in', 'the', 'amount', 'of', 'people', 'it', 'can', 'torture', 'and', 'kill', '.']\n",
      "Subject token  : dictatorship\n",
      "Token index    : 2\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 9:\n",
      "Sentence       : Chicago businessmen Bertram M. Lee and Peter Bynoe signed a new agreement to purchase the Denver Nuggets basketball team , but not as principal owners .\n",
      "Tokens         : ['Chicago', 'businessmen', 'Bertram', 'M.', 'Lee', 'and', 'Peter', 'Bynoe', 'signed', 'a', 'new', 'agreement', 'to', 'purchase', 'the', 'Denver', 'Nuggets', 'basketball', 'team', ',', 'but', 'not', 'as', 'principal', 'owners', '.']\n",
      "Subject token  : businessmen\n",
      "Token index    : 1\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 10:\n",
      "Sentence       : The Dorrance estate , auctioned off in a series of sales held over four days , included porcelains , furniture and paintings .\n",
      "Tokens         : ['The', 'Dorrance', 'estate', ',', 'auctioned', 'off', 'in', 'a', 'series', 'of', 'sales', 'held', 'over', 'four', 'days', ',', 'included', 'porcelains', ',', 'furniture', 'and', 'paintings', '.']\n",
      "Subject token  : estate\n",
      "Token index    : 2\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Total false positives: 641\n",
      "Total false negatives : 329\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import spacy\n",
    "\n",
    "# Load a subset of the OnTonotes5 dataset\n",
    "ds = load_dataset(\"tner/ontonotes5\", split=\"train\")\n",
    "\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "# Process each example in the dataset\n",
    "for example in ds:\n",
    "    tokens = example[\"tokens\"]       # e.g., [\"People\", \"start\", \"their\", \"own\", \"businesses\", ...]\n",
    "    tags = example[\"tags\"]           # e.g., [0, 0, 0, ...] with tag 4 indicating PERSON\n",
    "\n",
    "    # Reconstruct the sentence\n",
    "    sentence = \" \".join(tokens)\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    subject_token = None\n",
    "    # Extract the first subject from the spaCy parse\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if token.dep_ in ('nsubj', 'nsubjpass'):\n",
    "                subject_token = token\n",
    "                break\n",
    "        if subject_token:\n",
    "            break\n",
    "\n",
    "    # If no subject was found, skip this example\n",
    "    if subject_token is None:\n",
    "        continue\n",
    "\n",
    "    # Try to align the spaCy subject token with the dataset tokens (case-insensitive match)\n",
    "    try:\n",
    "        token_index = next(i for i, t in enumerate(tokens) if t.lower() == subject_token.text.lower())\n",
    "    except StopIteration:\n",
    "        continue\n",
    "\n",
    "    # Ground truth: tag 4 indicates PERSON\n",
    "    ground_truth_person = tags[token_index] == 4 or (\n",
    "        token_index > 0 and tags[token_index - 1] == 4\n",
    "    ) or (\n",
    "        token_index < len(tags) - 1 and tags[token_index + 1] == 4\n",
    "    )\n",
    "    # Model prediction: if spaCy labels the subject as PERSON, we predict PERSON\n",
    "    predicted_person = any(\n",
    "        ent.label_ == \"PERSON\" and subject_token.idx >= ent.start_char and subject_token.idx < ent.end_char\n",
    "        for ent in doc.ents\n",
    "    )\n",
    "\n",
    "    if predicted_person and not ground_truth_person:\n",
    "        false_positives.append({\n",
    "            \"sentence\": sentence,\n",
    "            \"subject_token\": subject_token.text,\n",
    "            \"token_index\": token_index,\n",
    "            \"tokens\": tokens,\n",
    "            \"predicted\": \"PERSON\",\n",
    "            \"ground_truth\": \"NOT_PERSON\"\n",
    "        })\n",
    "    elif (not predicted_person) and ground_truth_person:\n",
    "        false_negatives.append({\n",
    "            \"sentence\": sentence,\n",
    "            \"subject_token\": subject_token.text,\n",
    "            \"token_index\": token_index,\n",
    "            \"tokens\": tokens,\n",
    "            \"predicted\": \"NOT_PERSON\",\n",
    "            \"ground_truth\": \"PERSON\"\n",
    "        })\n",
    "\n",
    "# Print some misclassified examples for inspection\n",
    "print(\"False Positives (Model predicted PERSON but GT is NOT_PERSON):\")\n",
    "for i, example in enumerate(false_positives[:10]):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Sentence       :\", example[\"sentence\"])\n",
    "    print(\"Tokens         :\", example[\"tokens\"])\n",
    "    print(\"Subject token  :\", example[\"subject_token\"])\n",
    "    print(\"Token index    :\", example[\"token_index\"])\n",
    "    print(\"Predicted label:\", example[\"predicted\"])\n",
    "    print(\"Ground-truth   :\", example[\"ground_truth\"])\n",
    "\n",
    "print(\"\\n\\nFalse Negatives (Model predicted NOT_PERSON but GT is PERSON):\")\n",
    "for i, example in enumerate(false_negatives[:10]):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Sentence       :\", example[\"sentence\"])\n",
    "    print(\"Tokens         :\", example[\"tokens\"])\n",
    "    print(\"Subject token  :\", example[\"subject_token\"])\n",
    "    print(\"Token index    :\", example[\"token_index\"])\n",
    "    print(\"Predicted label:\", example[\"predicted\"])\n",
    "    print(\"Ground-truth   :\", example[\"ground_truth\"])\n",
    "\n",
    "print(\"\\nTotal false positives:\", len(false_positives))\n",
    "print(\"Total false negatives :\", len(false_negatives))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stygianphantom/Library/Python/3.9/lib/python/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_lg' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives (Model predicted PERSON but GT is NOT_PERSON):\n",
      "\n",
      "Example 1:\n",
      "Sentence       : He is known as the father of the U.S. - grown Granny Smith , a radically different apple that the conventional wisdom once said would never catch on .\n",
      "Tokens         : ['He', 'is', 'known', 'as', 'the', 'father', 'of', 'the', 'U.S.', '-', 'grown', 'Granny', 'Smith', ',', 'a', 'radically', 'different', 'apple', 'that', 'the', 'conventional', 'wisdom', 'once', 'said', 'would', 'never', 'catch', 'on', '.']\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 2:\n",
      "Sentence       : The scare over Alar , a growth regulator that makes apples redder and crunchier but may be carcinogenic , made consumers shy away from the Delicious , though they were less affected than the McIntosh .\n",
      "Tokens         : ['The', 'scare', 'over', 'Alar', ',', 'a', 'growth', 'regulator', 'that', 'makes', 'apples', 'redder', 'and', 'crunchier', 'but', 'may', 'be', 'carcinogenic', ',', 'made', 'consumers', 'shy', 'away', 'from', 'the', 'Delicious', ',', 'though', 'they', 'were', 'less', 'affected', 'than', 'the', 'McIntosh', '.']\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 3:\n",
      "Sentence       : Maybe we need a CIA version of the Miranda warning : You have the right to conceal your coup intentions , because we may rat on you .\n",
      "Tokens         : ['Maybe', 'we', 'need', 'a', 'CIA', 'version', 'of', 'the', 'Miranda', 'warning', ':', 'You', 'have', 'the', 'right', 'to', 'conceal', 'your', 'coup', 'intentions', ',', 'because', 'we', 'may', 'rat', 'on', 'you', '.']\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 4:\n",
      "Sentence       : Garish neon pachinko marquees blaze from the main streets and narrow alleys of cities and towns across the country .\n",
      "Tokens         : ['Garish', 'neon', 'pachinko', 'marquees', 'blaze', 'from', 'the', 'main', 'streets', 'and', 'narrow', 'alleys', 'of', 'cities', 'and', 'towns', 'across', 'the', 'country', '.']\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 5:\n",
      "Sentence       : The Senate convicted U.S. District Judge Alcee Hastings of Florida of eight impeachment articles , removing the 53 - year - old judge from his $ 89,500 - a - year , lifetime job .\n",
      "Tokens         : ['The', 'Senate', 'convicted', 'U.S.', 'District', 'Judge', 'Alcee', 'Hastings', 'of', 'Florida', 'of', 'eight', 'impeachment', 'articles', ',', 'removing', 'the', '53', '-', 'year', '-', 'old', 'judge', 'from', 'his', '$', '89,500', '-', 'a', '-', 'year', ',', 'lifetime', 'job', '.']\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 6:\n",
      "Sentence       : `` Here in south Texas we say Tie - vole - ee , '' my host gently corrects .\n",
      "Tokens         : ['``', 'Here', 'in', 'south', 'Texas', 'we', 'say', 'Tie', '-', 'vole', '-', 'ee', ',', \"''\", 'my', 'host', 'gently', 'corrects', '.']\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 7:\n",
      "Sentence       : National Semiconductor is getting ferroelectric technology from Krysalis Corp. in Albuquerque , N.M .\n",
      "Tokens         : ['National', 'Semiconductor', 'is', 'getting', 'ferroelectric', 'technology', 'from', 'Krysalis', 'Corp.', 'in', 'Albuquerque', ',', 'N.M', '.']\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 8:\n",
      "Sentence       : Several outfits -- including the Financial Programs , Franklin , and T. Rowe Price mutual - fund groups and the Edward D. Jones brokerage house -- are advertising `` college planner '' tables and charts that tell you how much you need to put aside regularly .\n",
      "Tokens         : ['Several', 'outfits', '--', 'including', 'the', 'Financial', 'Programs', ',', 'Franklin', ',', 'and', 'T.', 'Rowe', 'Price', 'mutual', '-', 'fund', 'groups', 'and', 'the', 'Edward', 'D.', 'Jones', 'brokerage', 'house', '--', 'are', 'advertising', '``', 'college', 'planner', \"''\", 'tables', 'and', 'charts', 'that', 'tell', 'you', 'how', 'much', 'you', 'need', 'to', 'put', 'aside', 'regularly', '.']\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 9:\n",
      "Sentence       : At a back - yard barbecue , for example , a friend boasts that she 'll only have to pay premiums on her John Hancock policy for seven years and that her death benefits will then be `` guaranteed . ''\n",
      "Tokens         : ['At', 'a', 'back', '-', 'yard', 'barbecue', ',', 'for', 'example', ',', 'a', 'friend', 'boasts', 'that', 'she', \"'ll\", 'only', 'have', 'to', 'pay', 'premiums', 'on', 'her', 'John', 'Hancock', 'policy', 'for', 'seven', 'years', 'and', 'that', 'her', 'death', 'benefits', 'will', 'then', 'be', '``', 'guaranteed', '.', \"''\"]\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "Example 10:\n",
      "Sentence       : Fierce bidding for young employees in Hong Kong is pushing up Cathay 's labor costs by 20 % a year for low - level staff , while experienced , skilled employees are leaving the colony as part of the brain drain .\n",
      "Tokens         : ['Fierce', 'bidding', 'for', 'young', 'employees', 'in', 'Hong', 'Kong', 'is', 'pushing', 'up', 'Cathay', \"'s\", 'labor', 'costs', 'by', '20', '%', 'a', 'year', 'for', 'low', '-', 'level', 'staff', ',', 'while', 'experienced', ',', 'skilled', 'employees', 'are', 'leaving', 'the', 'colony', 'as', 'part', 'of', 'the', 'brain', 'drain', '.']\n",
      "Predicted label: PERSON\n",
      "Ground-truth   : NOT_PERSON\n",
      "\n",
      "\n",
      "False Negatives (Model predicted NOT_PERSON but GT is PERSON):\n",
      "\n",
      "Example 1:\n",
      "Sentence       : It held that Testa is taxable on $ 44,400 of unreported income .\n",
      "Tokens         : ['It', 'held', 'that', 'Testa', 'is', 'taxable', 'on', '$', '44,400', 'of', 'unreported', 'income', '.']\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 2:\n",
      "Sentence       : Sheraton , a subsidiary of ITT Corp. , will have a 40 % share in the two hotels ; Pan American , a subsidiary of Pan Am Corp. , will have a 10 % share .\n",
      "Tokens         : ['Sheraton', ',', 'a', 'subsidiary', 'of', 'ITT', 'Corp.', ',', 'will', 'have', 'a', '40', '%', 'share', 'in', 'the', 'two', 'hotels', ';', 'Pan', 'American', ',', 'a', 'subsidiary', 'of', 'Pan', 'Am', 'Corp.', ',', 'will', 'have', 'a', '10', '%', 'share', '.']\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 3:\n",
      "Sentence       : To hear most U.S. growers tell it , we 'd still be in Paradise if the serpent had proffered one to Eve .\n",
      "Tokens         : ['To', 'hear', 'most', 'U.S.', 'growers', 'tell', 'it', ',', 'we', \"'d\", 'still', 'be', 'in', 'Paradise', 'if', 'the', 'serpent', 'had', 'proffered', 'one', 'to', 'Eve', '.']\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 4:\n",
      "Sentence       : And Beauregard was mentioned twice -- although very briefly and in passing . ''\n",
      "Tokens         : ['And', 'Beauregard', 'was', 'mentioned', 'twice', '--', 'although', 'very', 'briefly', 'and', 'in', 'passing', '.', \"''\"]\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 5:\n",
      "Sentence       : And her husband sometimes calls her `` Ducky . ''\n",
      "Tokens         : ['And', 'her', 'husband', 'sometimes', 'calls', 'her', '``', 'Ducky', '.', \"''\"]\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 6:\n",
      "Sentence       : `` When you 're at the club , you ask whether they 've spoken to ` G . '\n",
      "Tokens         : ['``', 'When', 'you', \"'re\", 'at', 'the', 'club', ',', 'you', 'ask', 'whether', 'they', \"'ve\", 'spoken', 'to', '`', 'G', '.', \"'\"]\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 7:\n",
      "Sentence       : Roe vs. Wade was the Supreme Court 's 1973 decision that recognized a woman 's right to abortion .\n",
      "Tokens         : ['Roe', 'vs.', 'Wade', 'was', 'the', 'Supreme', 'Court', \"'s\", '1973', 'decision', 'that', 'recognized', 'a', 'woman', \"'s\", 'right', 'to', 'abortion', '.']\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 8:\n",
      "Sentence       : Cargill thinks that even though the merchant has a contract stating that it wo n't bring this cocoa to market until after March 1991 , there is some evidence the contract has been modified .\n",
      "Tokens         : ['Cargill', 'thinks', 'that', 'even', 'though', 'the', 'merchant', 'has', 'a', 'contract', 'stating', 'that', 'it', 'wo', \"n't\", 'bring', 'this', 'cocoa', 'to', 'market', 'until', 'after', 'March', '1991', ',', 'there', 'is', 'some', 'evidence', 'the', 'contract', 'has', 'been', 'modified', '.']\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 9:\n",
      "Sentence       : The `` Guildford Four , '' three Irishmen and an Englishwoman , have been imprisoned since 1975 .\n",
      "Tokens         : ['The', '``', 'Guildford', 'Four', ',', \"''\", 'three', 'Irishmen', 'and', 'an', 'Englishwoman', ',', 'have', 'been', 'imprisoned', 'since', '1975', '.']\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Example 10:\n",
      "Sentence       : The Galileo spacecraft sped unerringly toward the planet Jupiter , while five astronauts aboard the space shuttle Atlantis measured the Earth 's ozone layer .\n",
      "Tokens         : ['The', 'Galileo', 'spacecraft', 'sped', 'unerringly', 'toward', 'the', 'planet', 'Jupiter', ',', 'while', 'five', 'astronauts', 'aboard', 'the', 'space', 'shuttle', 'Atlantis', 'measured', 'the', 'Earth', \"'s\", 'ozone', 'layer', '.']\n",
      "Predicted label: NOT_PERSON\n",
      "Ground-truth   : PERSON\n",
      "\n",
      "Total false positives: 363\n",
      "Total false negatives : 288\n",
      "True positives        : 11907\n",
      "True negatives        : 47366\n",
      "\n",
      "Precision: 0.970, Recall: 0.976, F1 Score: 0.973\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import spacy\n",
    "\n",
    "# Load a subset of the OnTonotes5 dataset\n",
    "ds = load_dataset(\"tner/ontonotes5\", split=\"train\")\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")  # Or whatever model you're using\n",
    "\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "true_positive = 0\n",
    "true_negative = 0\n",
    "\n",
    "# Process each example in the dataset\n",
    "for example in ds:\n",
    "    tokens = example[\"tokens\"]       # e.g., [\"People\", \"start\", \"their\", ...]\n",
    "    tags = example[\"tags\"]           # e.g., [0, 0, 4, ...]\n",
    "\n",
    "    sentence = \" \".join(tokens)\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    # Ground truth: if any tag == 4 (PERSON), then it's a PERSON sentence\n",
    "    ground_truth_person = 4 in tags\n",
    "\n",
    "    # Prediction: if any entity in the sentence is labeled PERSON by spaCy\n",
    "    predicted_person = any(ent.label_ == \"PERSON\" for ent in doc.ents)\n",
    "\n",
    "    # Evaluate outcomes\n",
    "    if predicted_person and not ground_truth_person:\n",
    "        false_positives.append({\n",
    "            \"sentence\": sentence,\n",
    "            \"tokens\": tokens,\n",
    "            \"predicted\": \"PERSON\",\n",
    "            \"ground_truth\": \"NOT_PERSON\"\n",
    "        })\n",
    "    elif not predicted_person and ground_truth_person:\n",
    "        false_negatives.append({\n",
    "            \"sentence\": sentence,\n",
    "            \"tokens\": tokens,\n",
    "            \"predicted\": \"NOT_PERSON\",\n",
    "            \"ground_truth\": \"PERSON\"\n",
    "        })\n",
    "    elif predicted_person and ground_truth_person:\n",
    "        true_positive += 1\n",
    "    elif not predicted_person and not ground_truth_person:\n",
    "        true_negative += 1\n",
    "\n",
    "# Metrics\n",
    "precision = true_positive / (true_positive + len(false_positives)) if (true_positive + len(false_positives)) > 0 else 0\n",
    "recall = true_positive / (true_positive + len(false_negatives)) if (true_positive + len(false_negatives)) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Print misclassifications\n",
    "print(\"False Positives (Model predicted PERSON but GT is NOT_PERSON):\")\n",
    "for i, example in enumerate(false_positives[:10]):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Sentence       :\", example[\"sentence\"])\n",
    "    print(\"Tokens         :\", example[\"tokens\"])\n",
    "    print(\"Predicted label:\", example[\"predicted\"])\n",
    "    print(\"Ground-truth   :\", example[\"ground_truth\"])\n",
    "\n",
    "print(\"\\n\\nFalse Negatives (Model predicted NOT_PERSON but GT is PERSON):\")\n",
    "for i, example in enumerate(false_negatives[:10]):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Sentence       :\", example[\"sentence\"])\n",
    "    print(\"Tokens         :\", example[\"tokens\"])\n",
    "    print(\"Predicted label:\", example[\"predicted\"])\n",
    "    print(\"Ground-truth   :\", example[\"ground_truth\"])\n",
    "\n",
    "# Summary\n",
    "print(\"\\nTotal false positives:\", len(false_positives))\n",
    "print(\"Total false negatives :\", len(false_negatives))\n",
    "print(\"True positives        :\", true_positive)\n",
    "print(\"True negatives        :\", true_negative)\n",
    "print(f\"\\nPrecision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stygianphantom/Library/Python/3.9/lib/python/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_lg' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'person_tokens': ['He'], 'is_directed_towards_someone': True}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Set of pronouns we consider as PERSONs\n",
    "PERSON_PRONOUNS = {\"you\", \"he\", \"she\", \"they\", \"him\", \"her\"}\n",
    "\n",
    "def detect_person_targets(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    person_tokens = []\n",
    "\n",
    "    for token in doc:\n",
    "        # Add pronouns like \"you\", \"he\", etc.\n",
    "        if token.text.lower() in PERSON_PRONOUNS:\n",
    "            person_tokens.append(token.text)\n",
    "    \n",
    "    # Add spaCy named PERSON entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            person_tokens.append(ent.text)\n",
    "\n",
    "    # Remove duplicates and preserve order\n",
    "    seen = set()\n",
    "    unique_persons = [p for p in person_tokens if not (p.lower() in seen or seen.add(p.lower()))]\n",
    "\n",
    "    return {\n",
    "        \"person_tokens\": unique_persons,\n",
    "        \"is_directed_towards_someone\": len(unique_persons) > 0\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
